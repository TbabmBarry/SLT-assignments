{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "from scipy.spatial import distance\n",
    "from operator import itemgetter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.genfromtxt(\n",
    "        'datasets/MNIST_train.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train[:,1:], train[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Cross validation on the complete dataset to tune k nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_score_large_dataset(train_X, train_y, cv=5, k=5, p=7):\n",
    "    fold_size, batch_numbers = int(train_y.shape[0]/cv), 20\n",
    "    indices = np.arange(train_y.shape[0])\n",
    "    np.random.RandomState(123).shuffle(indices)\n",
    "    results = []\n",
    "    for i in range(cv):\n",
    "        validation_idx = indices[i*fold_size:(i+1)*fold_size]\n",
    "        train_idx = np.concatenate((indices[:i*fold_size], indices[(i+1)*fold_size:]))\n",
    "        batch_train_idx = np.array_split(train_idx, batch_numbers)\n",
    "        batch_validation_idx = np.array_split(validation_idx, batch_numbers)\n",
    "        validation_y_pred = []\n",
    "        print(\"start:\",i,\"th cross validation\")\n",
    "        for u in range(batch_numbers):\n",
    "            print(\"start:\",u,\"th validation batch\")\n",
    "            validation_unit_batch_idx = batch_validation_idx[u]\n",
    "            level = [[] for i in range(validation_unit_batch_idx.shape[0])]\n",
    "            for j in range(batch_numbers):\n",
    "                train_unit_batch_idx = batch_train_idx[j]\n",
    "                distances=distance.cdist(train_X[validation_unit_batch_idx], train_X[train_unit_batch_idx], 'minkowski', p)\n",
    "                #validation_y_indices size:(validation_batch_size*train_batch_size)\n",
    "                k_indices = np.argsort(distances)[:,:k]\n",
    "                k_distances = np.array([distances[i,indices] for i, indices in zip(range(k_indices.shape[0]),k_indices)])\n",
    "                validation_y_indices = np.array([train_unit_batch_idx[indices] for indices in k_indices])\n",
    "                k_labels = np.array([train_y[indices] for indices in validation_y_indices]).astype(int)\n",
    "                \n",
    "                #k distances size:(validation_batch_size*k)\n",
    "                #k labels size:(validation_batch_size*k)                \n",
    "                # level element tuple size(k,k)\n",
    "                for i in range(validation_unit_batch_idx.shape[0]):\n",
    "                    level[i].extend(list(zip(k_distances[i],k_labels[i])))\n",
    "            \n",
    "            for i in range(validation_unit_batch_idx.shape[0]):\n",
    "                level[i].sort(key=itemgetter(0))\n",
    "                k_closests = [x[1] for x in level[i][:k]]            \n",
    "                validation_y_pred.append(np.argmax(np.bincount(k_closests)))\n",
    "           \n",
    "        validation_acc = np.sum(validation_y_pred == train_y[validation_idx])\n",
    "        print(f\"{i}th cross validation accuracy:{validation_acc:.3%}\\n\")\n",
    "        results.append(validation_acc/validation_idx.shape[0])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neighbors = np.linspace(1, 20, 20, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the change in the average accuracy according to k\n",
    "plt.figure(figsize = (15, 4))\n",
    "plt.title(\"k-NN\")\n",
    "plt.xticks(k_neighbors)\n",
    "plt.xlabel(\"Number of neighbors\")\n",
    "plt.ylabel(\"Average Accuracy\")\n",
    "results = []\n",
    "bn, bs = 0, 0\n",
    "for k in k_neighbors:\n",
    "    # k-fold cv from scratch for k-NN\n",
    "    print(\"start validate\", k,\" neighbors\")\n",
    "    acc = mean(cross_val_score_large_dataset(X_train, y_train, cv=10, k=k, p=7))\n",
    "    results.append(acc)\n",
    "    print(f\"\\nfinished, mean accuracy:{acc:.3%}\")\n",
    "    if (bs < acc): \n",
    "        bn, bs = k, acc\n",
    "plt.text(bn, bs, f'Neighbor:{bn}, Score:{bs:.3%}')\n",
    "plt.plot(k_neighbors, results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
